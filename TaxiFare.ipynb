{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkGYy7waWEmL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Taxi_fare.csv\")"
      ],
      "metadata": {
        "id": "it8uFKNtWne4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking whether there is any Null value in the DataFrame\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU-3DjC3XOgC",
        "outputId": "ae631bc3-6b1b-4307-a203-9ae7c94f77bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "trip_duration         0\n",
              "distance_traveled     0\n",
              "num_of_passengers     0\n",
              "fare                  0\n",
              "tip                   0\n",
              "miscellaneous_fees    0\n",
              "total_fare            0\n",
              "surge_applied         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving the target col to the Last\n",
        "target_col = df.pop(\"total_fare\")\n",
        "df[\"total_fare\"] = target_col"
      ],
      "metadata": {
        "id": "07WW21WkXWw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting features and Labels from the Dataset\n",
        "features = df.drop('total_fare', axis=1).values\n",
        "labels = df['total_fare'].values"
      ],
      "metadata": {
        "id": "48UNoVhMX9ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating class CustomDataset"
      ],
      "metadata": {
        "id": "M1-DZlpZYzVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,data,label):\n",
        "    self.data = data\n",
        "    self.label = label\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self,idx):\n",
        "    samples = {\"data\" : torch.tensor(self.data[idx] , dtype = torch.float32),\n",
        "               \"label\" : torch.tensor(self.label[idx],dtype = torch.float32)}\n",
        "    return samples"
      ],
      "metadata": {
        "id": "bvfdlbbtYTQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the instance of the class\n",
        "customdataset = CustomDataset(features,labels)"
      ],
      "metadata": {
        "id": "mf2xcNNEyEf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the input and target size inorder to give it to the model\n",
        "input_size = features.shape[1]\n",
        "target_size = 1\n",
        "print(f\"Size of the input is {input_size} , target size is {target_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ3J96IWySNO",
        "outputId": "013fc569-2ebe-4114-e3a6-1cc88c5a5ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the input is 7 , target size is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the model"
      ],
      "metadata": {
        "id": "KMV0ORhtxvNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the reproducability\n",
        "torch.manual_seed(42)\n",
        "#model\n",
        "model = nn.Linear(input_size,target_size)"
      ],
      "metadata": {
        "id": "3wZExhHPYVtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFLoPeBvvETM",
        "outputId": "a525ef3b-df35-4333-916b-812a888aa372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 0.2890,  0.3137, -0.0885,  0.3472, -0.0828,  0.0763, -0.1840]])),\n",
              "             ('bias', tensor([0.2220]))])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the Optimizer and Loss function"
      ],
      "metadata": {
        "id": "jRmecnM20nYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
      ],
      "metadata": {
        "id": "NDGilQ8b0meS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_workers = 4\n",
        "data_loader = DataLoader(customdataset,batch_size = batch_size, num_workers = 10 ,shuffle=True)"
      ],
      "metadata": {
        "id": "xjp5q2oJ0Tim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "epoch = 100\n",
        "#1\n",
        "for i in range(epoch):\n",
        "  for samples in data_loader:\n",
        "    data,label = samples[\"data\"] , samples[\"label\"]\n",
        "    model.train()\n",
        "    #ForwardPass\n",
        "    y_pred = model(data)\n",
        "\n",
        "    #Loss\n",
        "    loss = loss_fn(y_pred,label)\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    #Update weights\n",
        "    optimizer.step()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr4hYHVC1qvM",
        "outputId": "827c7004-a266-466a-8a93-1c259041f1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([73])) that is different to the input size (torch.Size([73, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRLC__C_17fO",
        "outputId": "ef8b8e36-1e16-4b1b-b987-b654c5811ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(424.6856, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8R7_zztDak6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}